#!/usr/bin/env python3
"""
Test the fixed scrapers to ensure they're working
"""

import requests
from bs4 import BeautifulSoup
import time
import logging
from urllib.parse import urljoin, urlparse
import re

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class WorkingOrchidScraper:
    """Fixed scraper that actually works"""
    
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (compatible; OrchidBot/1.0; Educational/Research)'
        })
        self.collected_count = 0
    
    def test_gary_yong_gee_scraper(self):
        """Test Gary Yong Gee scraper with actual functionality"""
        logger.info("üåø Testing Gary Yong Gee scraper...")
        
        base_url = "https://orchids.yonggee.name"
        collected = 0
        
        try:
            # Try to access the main page
            response = self.session.get(base_url, timeout=10)
            logger.info(f"Gary site response: {response.status_code}")
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.content, 'html.parser')
                
                # Look for orchid images or links
                images = soup.find_all('img')
                links = soup.find_all('a')
                
                logger.info(f"Found {len(images)} images, {len(links)} links")
                
                # Count potential orchid content
                orchid_content = 0
                for img in images:
                    src = img.get('src', '')
                    alt = img.get('alt', '').lower()
                    if any(term in alt for term in ['orchid', 'flower', 'species']):
                        orchid_content += 1
                
                collected = orchid_content
                logger.info(f"‚úÖ Gary scraper: Found {collected} potential orchid images")
            else:
                logger.warning(f"Gary site returned {response.status_code}")
                
        except Exception as e:
            logger.error(f"Gary scraper error: {str(e)}")
            
        return collected
    
    def test_roberta_fox_scraper(self):
        """Test Roberta Fox scraper with actual functionality"""
        logger.info("üì∏ Testing Roberta Fox scraper...")
        
        base_url = "http://orchidcentral.org"
        collected = 0
        
        try:
            # Try the main orchid central page
            response = self.session.get(base_url, timeout=10)
            logger.info(f"Roberta site response: {response.status_code}")
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.content, 'html.parser')
                
                # Look for gallery links
                gallery_links = []
                for link in soup.find_all('a'):
                    href = link.get('href', '')
                    if 'group' in href.lower() or 'gallery' in href.lower():
                        gallery_links.append(href)
                
                logger.info(f"Found {len(gallery_links)} potential gallery links")
                
                # Test one gallery link
                if gallery_links:
                    test_url = urljoin(base_url, gallery_links[0])
                    try:
                        gallery_response = self.session.get(test_url, timeout=10)
                        if gallery_response.status_code == 200:
                            gallery_soup = BeautifulSoup(gallery_response.content, 'html.parser')
                            images = gallery_soup.find_all('img')
                            collected = len(images)
                            logger.info(f"‚úÖ Roberta scraper: Test gallery has {collected} images")
                    except:
                        pass
                        
        except Exception as e:
            logger.error(f"Roberta scraper error: {str(e)}")
            
        return collected
    
    def test_ron_parsons_scraper(self):
        """Test Ron Parsons scraper"""
        logger.info("üåü Testing Ron Parsons scraper...")
        
        base_url = "https://www.flowershots.net/"
        collected = 0
        
        try:
            # Test a specific orchid page
            test_url = "https://www.flowershots.net/Dendrobium_species.html"
            response = self.session.get(test_url, timeout=10)
            logger.info(f"Ron Parsons response: {response.status_code}")
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.content, 'html.parser')
                images = soup.find_all('img')
                
                # Count actual orchid images
                orchid_images = 0
                for img in images:
                    src = img.get('src', '')
                    if '.jpg' in src.lower() or '.jpeg' in src.lower():
                        orchid_images += 1
                
                collected = orchid_images
                logger.info(f"‚úÖ Ron Parsons scraper: Found {collected} images")
                
        except Exception as e:
            logger.error(f"Ron Parsons scraper error: {str(e)}")
            
        return collected

def main():
    """Test all fixed scrapers"""
    print("üîß TESTING FIXED SCRAPERS:")
    print("=" * 50)
    
    scraper = WorkingOrchidScraper()
    
    # Test each scraper
    gary_results = scraper.test_gary_yong_gee_scraper()
    roberta_results = scraper.test_roberta_fox_scraper()
    ron_results = scraper.test_ron_parsons_scraper()
    
    print()
    print("üìä SCRAPER TEST RESULTS:")
    print(f"  Gary Yong Gee: {gary_results} items found")
    print(f"  Roberta Fox: {roberta_results} items found")
    print(f"  Ron Parsons: {ron_results} items found")
    print(f"  Total potential: {gary_results + roberta_results + ron_results}")
    
    if gary_results > 0 or roberta_results > 0 or ron_results > 0:
        print("‚úÖ SCRAPERS ARE WORKING - Ready for database integration!")
    else:
        print("‚ö†Ô∏è Scrapers need further debugging")

if __name__ == "__main__":
    main()